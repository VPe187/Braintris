# Tetris osztály konstansai
# Jutalom
REWARD_FULLROW = 100
REWARD_NEARLY_FULLROW = 40
REWARD_PLACE_WITHOUT_HOLE = 60
REWARD_DROP_LOWER = 20
# Büntetés
REWARD_DROPPED_ELEMENTS = 0.01
REWARD_AVG_DENSITY = 100
REWARD_NUMBER_OF_HOLES = 0.1
REWARD_SURROUNDED_HOLES = 0.2
REWARD_DROP_HIGHER = 1
REWARD_BLOCKED_ROW = 1.2
REWARD_BUMPINESS = 0.3
REWARD_AVG_COLUMN_HEIGHT = 0.5
REWARD_MAXIMUM_HEIGHT = 0.9

# NeuralNetwork osztály konstansai
FILE_NAME = brain.dat
FEED_DATA_SIZE = 30
OUTPUT_NODES = 4
NORMALIZE_FEED_DATA = True
LAYER_NAMES = INP,H1,H2,H3,H4,OUT
LAYER_SIZES = ${FEED_DATA_SIZE},64,32,16,32,${OUTPUT_NODES}
LAYER_ACTIVATIONS = LEAKY_RELU,LEAKY_RELU,LEAKY_RELU,LEAKY_RELU,LINEAR
WEIGHT_INIT_STRATEGIES = HE,HE,HE,HE,XAVIER
BATCH_NORMS = true:1.0:0.0,true:1.0:0.0,true:1.0:0.0,true:1.0:0.0,false:1.0:0.0
L2_REGULARIZATION = 0.0,0.0,0.0,0.0,0.0,0.0
CLIP_MIN = -1.0
CLIP_MAX = 1.0
CLIP_NORM = 1.0
INITIAL_LEARNING_RATE = 0.01
LEARNING_RATE_DECAY = 0.999
MIN_LEARNING_RATE = 0.0001
INITIAL_DISCOUNT_FACTOR = 0.5
MAX_DISCOUNT_FACTOR = 0.99
DISCOUNT_FACTOR_INCREMENT = 0.0001
INITIAL_EPSILON = 0.6
EPSILON_DECAY = 0.99
MIN_EPSILON = 0.01
MIN_Q = -500
MAX_Q = 500
MOVING_AVERAGE_WINDOW = 1000
USE_EXPERIENCE = false
EXPERIENCE_REPLAY_CAPACITY = 10000
EXPERIENCE_BATCH_SIZE = 32