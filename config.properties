# NeuralNetwork osztály konstansai
FILE_NAME = brain.dat
FEED_DATA_SIZE = 24
OUTPUT_NODES = 15
NORMALIZE_FEED_DATA = true
# MINMAX / ZSCORE
FEED_DATA_NORMALIZER = MINMAX
LAYER_NAMES = INP,H1,H2,H3,OUT
LAYER_SIZES = ${FEED_DATA_SIZE},48,64,48,32,${OUTPUT_NODES}
# SIGMOID, TANH, RELU, LEAKY_RELU, ELU, GELU, LINEAR, SWISH, MISH, SOFTMAX, SOFTMAX_SPLIT
LAYER_ACTIVATIONS = RELU,RELU,RELU,RELU,SOFTMAX_SPLIT
# RANDOM, XAVIER, HE, UNIFORM, ZERO
WEIGHT_INIT_STRATEGIES = HE,HE,HE,HE,HE
# INP-H1,H1-H2,H2-H3,H3-OUT
MINIMUM_BATCH_SIZE = 32
BATCH_NORMS = true:1.0:0.0,true:1.0:0.0,true:1.0:0.0,true:1.1:0.0,false:1.0:0.0
BATCH_DEFAULT_EPSILON = 1e-4
BATCH_DEFAULT_MOMENTUM = 0.9
# INP, H1, H2, H3, H4, OUT
L2_REGULARIZATION = 0.0000, 0.00001, 0.00001, 0.00001, 0.00001, 0.0
CLIP_MIN = -2.0
CLIP_MAX = 2.0
CLIP_NORM = 2.0
GRADIENT_SCALE = 1.2
INITIAL_LEARNING_RATE = 1.0
LEARNING_RATE_DECAY = 0.9999
MIN_LEARNING_RATE = 0.00001
INITIAL_DISCOUNT_FACTOR = 0.5
MAX_DISCOUNT_FACTOR = 0.99
DISCOUNT_FACTOR_INCREMENT = 0.0001
INITIAL_EPSILON = 0.00
EPSILON_DECAY = 0.9999
MIN_EPSILON = 0.00
MIN_Q = -50
MAX_Q = 50
MOVING_AVERAGE_WINDOW = 1000
USE_EXPERIENCE = false
EXPERIENCE_REPLAY_CAPACITY = 10000
EXPERIENCE_BATCH_SIZE = 64

# Tetris osztály konstansai
# Jutalom
REWARD_FULLROW = 300
REWARD_NEARLY_FULLROW = 150
REWARD_PLACE_WITHOUT_HOLE = 100
REWARD_DROP_LOWER = 50
# Büntetés
REWARD_DROPPED_ELEMENTS = 0.1
REWARD_AVG_DENSITY = 5
REWARD_DROP_HIGHER = 0.3
REWARD_NUMBER_OF_HOLES = 0.5
REWARD_SURROUNDED_HOLES = 0.8
REWARD_BLOCKED_ROW = 0.5
REWARD_BUMPINESS = 0.4
REWARD_AVG_COLUMN_HEIGHT = 5
REWARD_MAXIMUM_HEIGHT = 0.3