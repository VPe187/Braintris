# NeuralNetwork osztály konstansai
FILE_NAME = brain.dat
FEED_DATA_SIZE = 29
OUTPUT_NODES = 15
NORMALIZE_FEED_DATA = true
# MINMAX / ZSCORE
FEED_DATA_NORMALIZER = ZSCORE
LAYER_NAMES = INP,H1,H2,H3,OUT
LAYER_SIZES = ${FEED_DATA_SIZE},90,63,30,30,${OUTPUT_NODES}
# SIGMOID, TANH, RELU, LEAKY_RELU, ELU, GELU, LINEAR, SWISH, MISH, SOFTMAX
LAYER_ACTIVATIONS = LEAKY_RELU,LEAKY_RELU,LEAKY_RELU,LEAKY_RELU,TANH
# RANDOM, XAVIER, HE, UNIFORM, ZERO
WEIGHT_INIT_STRATEGIES = HE,HE,HE,HE,XAVIER
# INP-H1,H1-H2,H2-H3,H3-OUT
BATCH_NORMS = true:1.0:0.0,true:1.0:0.0,true:1.0:0.0,true:1.1:0.0,true:1.1:0.1
BATCH_DEFAULT_EPSILON = 1e-4
BATCH_DEFAULT_MOMENTUM = 0.9
# INP, H1, H2, H3, OUT
L2_REGULARIZATION = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0
CLIP_MIN = -1.0
CLIP_MAX = 1.0
CLIP_NORM = 2.0
GRADIENT_SCALE = 1.2
INITIAL_LEARNING_RATE = 0.01
LEARNING_RATE_DECAY = 0.9999
MIN_LEARNING_RATE = 0.00001
INITIAL_DISCOUNT_FACTOR = 0.5
MAX_DISCOUNT_FACTOR = 0.99
DISCOUNT_FACTOR_INCREMENT = 0.0001
INITIAL_EPSILON = 0.1
EPSILON_DECAY = 0.999
MIN_EPSILON = 0.01
MIN_Q = -500
MAX_Q = 500
MOVING_AVERAGE_WINDOW = 1000
USE_EXPERIENCE = true
EXPERIENCE_REPLAY_CAPACITY = 10000
EXPERIENCE_BATCH_SIZE = 64

# Tetris osztály konstansai
# Jutalom
REWARD_FULLROW = 100
REWARD_NEARLY_FULLROW = 60
REWARD_PLACE_WITHOUT_HOLE = 80
REWARD_DROP_LOWER = 30
# Büntetés
REWARD_DROPPED_ELEMENTS = 0.01
REWARD_AVG_DENSITY = 10
REWARD_DROP_HIGHER = 0.2
REWARD_NUMBER_OF_HOLES = 0.3
REWARD_SURROUNDED_HOLES = 0.4
REWARD_BLOCKED_ROW = 0.5
REWARD_BUMPINESS = 0.8
REWARD_AVG_COLUMN_HEIGHT = 0.8
REWARD_MAXIMUM_HEIGHT = 0.1