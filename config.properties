# NeuralNetwork osztály konstansai
FILE_NAME = brain.dat
FEED_DATA_SIZE = 24
OUTPUT_NODES = 15
NORMALIZE_FEED_DATA = true
# MINMAX / ZSCORE
FEED_DATA_NORMALIZER = MINMAX
LAYER_NAMES = INP,H1,H2,H3,OUT
LAYER_SIZES = ${FEED_DATA_SIZE},60,60,30,30,${OUTPUT_NODES}
# SIGMOID, TANH, RELU, LEAKY_RELU, ELU, GELU, LINEAR, SWISH, MISH, SOFTMAX, SOFTMAX_SPLIT
LAYER_ACTIVATIONS = RELU,RELU,RELU,RELU,SOFTMAX_SPLIT
# RANDOM, XAVIER, HE, UNIFORM, ZERO
WEIGHT_INIT_STRATEGIES = HE,HE,HE,HE,XAVIER
# INP-H1,H1-H2,H2-H3,H3-OUT
BATCH_NORMS = true:1.0:0.0,true:1.0:0.0,true:1.0:0.0,true:1.1:0.0,true:1.1:0.1
BATCH_DEFAULT_EPSILON = 1e-4
BATCH_DEFAULT_MOMENTUM = 0.9
# INP, H1, H2, H3, H4, OUT
L2_REGULARIZATION = 0.0, 0.0001, 0.0001, 0.0001, 0.0001, 0.0
CLIP_MIN = -0.5
CLIP_MAX = 0.5
CLIP_NORM = 0.5
GRADIENT_SCALE = 2
INITIAL_LEARNING_RATE = 0.1
LEARNING_RATE_DECAY = 0.9999
MIN_LEARNING_RATE = 0.00001
INITIAL_DISCOUNT_FACTOR = 0.5
MAX_DISCOUNT_FACTOR = 0.99
DISCOUNT_FACTOR_INCREMENT = 0.0001
INITIAL_EPSILON = 0.1
EPSILON_DECAY = 0.9999
MIN_EPSILON = 0.01
MIN_Q = -500
MAX_Q = 500
MOVING_AVERAGE_WINDOW = 1000
USE_EXPERIENCE = true
EXPERIENCE_REPLAY_CAPACITY = 10000
EXPERIENCE_BATCH_SIZE = 64

# Tetris osztály konstansai
# Jutalom
REWARD_FULLROW = 100
REWARD_NEARLY_FULLROW = 60
REWARD_PLACE_WITHOUT_HOLE = 80
REWARD_DROP_LOWER = 30
# Büntetés
REWARD_DROPPED_ELEMENTS = 0.01
REWARD_AVG_DENSITY = 10
REWARD_DROP_HIGHER = 0.2
REWARD_NUMBER_OF_HOLES = 0.2
REWARD_SURROUNDED_HOLES = 0.2
REWARD_BLOCKED_ROW = 0.2
REWARD_BUMPINESS = 0.2
REWARD_AVG_COLUMN_HEIGHT = 10
REWARD_MAXIMUM_HEIGHT = 0.1